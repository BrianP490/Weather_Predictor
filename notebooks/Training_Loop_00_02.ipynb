{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c7208c",
   "metadata": {},
   "source": [
    "# Creating Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d4ff82",
   "metadata": {},
   "source": [
    "## VERSIONS\n",
    "\n",
    "- 00_02: \n",
    "    - Refactor DataPipeline functions\n",
    "    - Updated to align more with PEP8\n",
    "    - Created to try new Model architecture and align with project template\n",
    "- 00_01: \n",
    "    - Diagnosing Exploding Gradients\n",
    "- 00_00: \n",
    "    - Initial Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38313aff",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10f3e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from importlib.metadata import version\n",
    "from importlib.metadata import PackageNotFoundError # For handling package version errors\n",
    "from logging import Logger # For type hinting\n",
    "from typing import List, Optional # For type hinting\n",
    "import json\n",
    "import logging\n",
    "import argparse\n",
    "import time\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from pandas.errors import ParserError\n",
    "import torch\n",
    "from torch.nn import Module # For type hinting\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e8542d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 2.3.1\n",
      "seaborn version: 0.13.2\n",
      "matplotlib version: 3.10.5\n",
      "torch version: 2.5.1\n",
      "joblib version: 1.5.1\n",
      "tqdm version: 4.67.1\n"
     ]
    }
   ],
   "source": [
    "package_list = ['pandas', 'seaborn', 'matplotlib', 'torch', 'joblib', 'tqdm']\n",
    "for package in package_list:\n",
    "    try:\n",
    "        print(f\"{package} version: {version(package)}\") # Raises PackageNotFoundError if not found\n",
    "    except PackageNotFoundError:\n",
    "        print(f\"❌ Package '{package}' not found. Please install it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b0e27",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bf5e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = '../configs/config.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbefac4",
   "metadata": {},
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20070b14",
   "metadata": {},
   "source": [
    "### Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b348b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"Dataset class For the CA Weather Fire Dataset\"\"\"\n",
    "    def __init__(self, csv_file=\"../Data/CA_Weather_Fire_Dataset_Cleaned.csv\"):\n",
    "        \"\"\"Initializer for the Dataset class.\n",
    "        Args:\n",
    "            csv_file (str): Path to the CSV file containing the dataset.\n",
    "            label_column (str): The name of the column indicating the label.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.data = pd.read_csv(csv_file)   # Assign a pandas data frame\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"File not found: {csv_file}\")\n",
    "\n",
    "        # Define feature and label columns\n",
    "        self.feature_columns = self.data.columns.drop(\"MAX_TEMP\")\n",
    "        self.label_column = \"MAX_TEMP\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Returns a tuple (features, label) for the given index.\n",
    "        Args:\n",
    "            index (int): Index of the data sample to retrieve.\n",
    "        Returns:\n",
    "            tuple: (features, label) where features is a tensor of input features and\n",
    "            label is the corresponding label.\n",
    "        \"\"\"\n",
    "        features = self.data.loc[index, self.feature_columns].values\n",
    "\n",
    "        label = self.data.loc[index, self.label_column] # Extract the label for the given index\n",
    "        return (\n",
    "            torch.tensor(features, dtype=torch.float),\n",
    "            torch.tensor(label, dtype=torch.float)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the amount of samples in the dataset.\"\"\"\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452cadc6",
   "metadata": {},
   "source": [
    "### Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f28d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df: pd.DataFrame, logger: Logger) -> pd.DataFrame:\n",
    "    \"\"\"Cleans the input DataFrame.\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame to be cleaned.\n",
    "        logger (Logger): Logger object for logging information.\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    show_dataframe_info = True  # Set to True to log DataFrame info\n",
    "\n",
    "    # Log the initial state of the DataFrame\n",
    "    if show_dataframe_info:\n",
    "        logger.info(f\"Initial DataFrame shape: {df.shape}\")\n",
    "        buffer = io.StringIO()  # Create a buffer to capture the info output\n",
    "        df.info(buf=buffer) # Store the output into the buffer\n",
    "        logger.info(f\"Initial DataFrame info:\\n \" + buffer.getvalue())\n",
    "    \n",
    "    # Example cleaning steps (customize as needed)\n",
    "    df = df.drop_duplicates() # Remove duplicates\n",
    "\n",
    "    # Handle missing values (if any)\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        logger.info(\"Handling missing values...\")\n",
    "        df = df.dropna()  # Example: Drop rows with missing values\n",
    "        logger.info(f\"DataFrame shape after dropping missing values: {df.shape}\")\n",
    "    \n",
    "    if show_dataframe_info:\n",
    "        # Reinitialize the buffer to clear any previous content in order to log the final dataframe info\n",
    "        buffer = io.StringIO()\n",
    "        df.info(buf=buffer)\n",
    "        logger.info(f\"Final DataFrame info:\\n \" + buffer.getvalue())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e2bb08",
   "metadata": {},
   "source": [
    "### Data Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81904364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(\n",
    "        logger: Logger, dataset_url: str, root_data_dir: str= \"../Data\",\n",
    "        data_file_path: str=\"Dataset.csv\", data_splits_dir: str=\"DataSplits\",\n",
    "        scaler_dir = \"Scalers\", target_column: str=\"Target\",\n",
    "        extra_dropped_columns: Optional[List[str]]=None, batch_size: int=64,\n",
    "        num_workers: int=0, pin_memory: bool=False, drop_last: bool=True) -> tuple[Dataset,\n",
    "                                                                                   Dataset,\n",
    "                                                                                   Dataset,\n",
    "                                                                                   DataLoader,\n",
    "                                                                                   DataLoader,\n",
    "                                                                                   DataLoader,\n",
    "                                                                                   StandardScaler]:\n",
    "    \"\"\"This function prepares the train, test, and validation datasets.\n",
    "    Args:\n",
    "        logger (Logger): The logger instance to log messages.\n",
    "        dataset_url (str): The URL to download the dataset from, if not found locally.\n",
    "        root_data_dir (str): The root of the Data Directory\n",
    "        data_file_path (str): The name of the original dataset (with .csv file extension).\n",
    "        data_splits_dir (str): Path to the train, test, and validation datasets.\n",
    "        scaler_dir (str): Path to the feature and label scalers.\n",
    "        target_column (str): The name of the target column to predict.\n",
    "        extra_dropped_columns (List[str], optional): Additional columns to drop from the features.\n",
    "        batch_size (int): The dataloader's batch_size.\n",
    "        num_workers (int): The dataloader's number of workers.\n",
    "        pin_memory (bool): The dataloader's pin memory option.\n",
    "        drop_last (bool): The dataloader's drop_last option.\n",
    "\n",
    "    Returns: \n",
    "        train_dataset (Dataset): Dataset Class for the training dataset.\n",
    "        test_dataset (Dataset): Dataset Class for the test dataset.\n",
    "        validation_dataset (Dataset): Dataset Class for the validation dataset.\n",
    "        train_dataloader (DataLoader): The train dataloader.\n",
    "        test_dataloader (DataLoader): The test dataloader.\n",
    "        validation_dataloader (DataLoader): The validation dataloader.\n",
    "        feature_scaler (MinMaxScaler): The scaler used to scale the features of the model input.\n",
    "    \"\"\"\n",
    "    # Check for empty strings at the beginning\n",
    "    if not root_data_dir or not data_file_path or not data_splits_dir:\n",
    "        raise ValueError(\"File and directory paths cannot be empty strings.\")\n",
    "    logger.info(f\"root_data_dir: {root_data_dir}\")\n",
    "    DATA_ROOT = Path(root_data_dir)\n",
    "\n",
    "    DATA_CLEAN_PATH = DATA_ROOT / data_file_path # Set the path to the complete dataset\n",
    "\n",
    "    if DATA_CLEAN_PATH.exists():\n",
    "        logger.info(f\"CSV file detected, reading from '{DATA_ROOT}'\")\n",
    "        df = pd.read_csv(DATA_CLEAN_PATH)\n",
    "    else:\n",
    "        logger.info(f\"Downloading CSV file from Internet and saving into '{DATA_ROOT}'\")\n",
    "        try:\n",
    "            os.makedirs(DATA_ROOT, exist_ok=True)       # Create the Data Root Directory\n",
    "            df = pd.read_csv(dataset_url)  # Download and read the data into a pandas dataframe\n",
    "\n",
    "            # Clean the data before saving\n",
    "            df = clean_data(df, logger)\n",
    "\n",
    "            df.to_csv(DATA_CLEAN_PATH, index=False)     # Save the file, omitting saving the row index\n",
    "        \n",
    "        except OSError as e:\n",
    "            raise RuntimeError(f\"OS error occurred: {e}\")\n",
    "        except ParserError:\n",
    "            raise RuntimeError(f\"Failed to parse CSV from '{dataset_url}'\")\n",
    "        except ValueError as e:\n",
    "            raise RuntimeError(f\"Data cleaning error: {e}\")\n",
    "        except Exception:\n",
    "            raise RuntimeError(f\"An unexpected error occurred when downloading or saving the \"\n",
    "                               f\"dataset from '{dataset_url}' to '{DATA_CLEAN_PATH}'\")\n",
    "\n",
    "\n",
    "     # Define the paths for the data splits and scalers\n",
    "    DATA_SPLITS_DIR = DATA_ROOT / data_splits_dir\n",
    "    SCALER_DIR = DATA_ROOT / scaler_dir\n",
    "\n",
    "    TRAIN_DATA_PATH = DATA_SPLITS_DIR / \"train.csv\"\n",
    "    TEST_DATA_PATH = DATA_SPLITS_DIR / \"test.csv\"\n",
    "    VALIDATION_DATA_PATH = DATA_SPLITS_DIR / \"val.csv\"\n",
    "\n",
    "    FEATURE_SCALER_PATH = SCALER_DIR / \"feature-scaler.joblib\"\n",
    "    # LABEL_SCALER_PATH = SCALER_DIR / \"label-scaler.joblib\"\n",
    "    # Define the columns to drop from the features\n",
    "    columns_to_drop = [target_column] + extra_dropped_columns\n",
    "\n",
    "    if (os.path.exists(TRAIN_DATA_PATH) and\n",
    "        os.path.exists(TEST_DATA_PATH) and\n",
    "        os.path.exists(VALIDATION_DATA_PATH)):\n",
    "        print(f\"Train, Test, and Validation csv datasets detected in '{DATA_SPLITS_DIR}', skipping generation and loading scaler(s)\")\n",
    "        try:\n",
    "            feature_scaler = joblib.load(FEATURE_SCALER_PATH)\n",
    "        except FileNotFoundError as e:\n",
    "            raise RuntimeError(f\"Scaler file not found: {e}\")\n",
    "        except EOFError as e:\n",
    "            raise RuntimeError(f\"Scaler file appears to be empty or corrupted: {e}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"An unexpected error occurred when loading scalers: {e}\")\n",
    "    else:\n",
    "        logger.info(f\"Datasets not found in '{DATA_SPLITS_DIR}' or incomplete. Generating datasets...\")\n",
    "        # os.makedirs(MODEL_ROOT, exist_ok=True)\n",
    "        os.makedirs(DATA_SPLITS_DIR, exist_ok=True)     # Create the Data Splits Parent Directory\n",
    "        os.makedirs(SCALER_DIR, exist_ok=True)     # Create the Scaler Parent Directory\n",
    "\n",
    "        # Initialize the StandardScaler\n",
    "        feature_scaler = StandardScaler()\n",
    "        # label_scaler = MinMaxScaler()\n",
    "\n",
    "        try:\n",
    "            df_features = df.drop(columns=columns_to_drop, inplace=False)\n",
    "            df_labels = df[[target_column]]     # Instead of returning a pandas Series using \"[]\", return a dataframe using the \"[[]]\" to get a shape with (-1,1)\n",
    "        except KeyError as e:\n",
    "            raise KeyError(f\"One or more specified columns to drop do not exist in the DataFrame: {e}\")\n",
    "\n",
    "        # split your data before scaling, shuffling the data\n",
    "        X_train, X_inter, Y_train, Y_inter = train_test_split(df_features, df_labels, test_size=0.1, random_state=42)\n",
    "        X_validation, X_test, Y_validation, Y_test = train_test_split(X_inter, Y_inter, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "        # Fit the scaler on the training data ONLY. Need to use the scaler on all inputs that the model receives.\n",
    "        # This means the mean and standard deviation are calculated from the training set.\n",
    "        feature_scaler.fit(X_train)\n",
    "        # label_scaler.fit(Y_train)\n",
    "\n",
    "        # Transform the training, validation, and test data using the fitted scaler\n",
    "        X_train_scaled = feature_scaler.transform(X_train)\n",
    "        X_test_scaled = feature_scaler.transform(X_test)\n",
    "        X_validation_scaled = feature_scaler.transform(X_validation)\n",
    "\n",
    "        # Y_validation_scaled = label_scaler.transform(Y_validation)\n",
    "        # X_test_scaled = feature_scaler.transform(X_test)\n",
    "        # Y_test_scaled = label_scaler.transform(Y_test)\n",
    "\n",
    "        # Save the fitted scaler object\n",
    "        try:\n",
    "            joblib.dump(feature_scaler, FEATURE_SCALER_PATH)\n",
    "            logger.info(f\"Feature scaler stored in: ({FEATURE_SCALER_PATH})\")\n",
    "            # joblib.dump(feature_scaler, FEATURE_SCALER_PATH)\n",
    "            # logger.info(f\"Feature scaler stored in: ({FEATURE_SCALER_PATH})\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"An unexpected error occurred when saving Scaler(s): {e}\")\n",
    "\n",
    "        logger.info(f\"Train Features Scaled Shape: {X_train_scaled.shape}\")\n",
    "\n",
    "        logger.info(f\"Train Labels Shape: {Y_train.shape}\")\n",
    "\n",
    "        logger.info(f\"Validation Features Scaled Shape: {X_validation_scaled.shape}\")\n",
    "\n",
    "        logger.info(f\"Validation Labels Shape: {Y_validation.shape}\")\n",
    "\n",
    "        logger.info(f\"Test Features Scaled Shape: {X_test_scaled.shape}\")\n",
    "\n",
    "        logger.info(f\"Test Labels Shape: {Y_test.shape}\")\n",
    "\n",
    "        # Define the column names of the features and label\n",
    "        features_names = df_features.columns\n",
    "        # label_name = df_labels.columns\n",
    "\n",
    "        # Scale the rest of the data; returns numpy arrays\n",
    "        X_train_df = pd.DataFrame(X_train_scaled, columns=features_names)\n",
    "        X_test_df = pd.DataFrame(X_test_scaled, columns=features_names)\n",
    "        X_validation_df = pd.DataFrame(X_validation_scaled, columns=features_names)\n",
    "\n",
    "        # Y_train_df = pd.DataFrame(Y_train_scaled, columns=label_name)\n",
    "        # Y_test_df = pd.DataFrame(Y_test_scaled, columns=label_name)\n",
    "        # Y_validation_df = pd.DataFrame(Y_validation_scaled, columns=label_name)\n",
    "\n",
    "        # Concatenate the features and labels back into a single DataFrame for each set\n",
    "        train_data_frame = pd.concat([X_train_df, Y_train.reset_index(drop=True)], axis=1)\n",
    "        test_data_frame = pd.concat([X_test_df, Y_test.reset_index(drop=True)], axis=1)\n",
    "        validation_data_frame = pd.concat([X_validation_df, Y_validation.reset_index(drop=True)], axis=1)\n",
    "\n",
    "        # Saving the split data to csv files\n",
    "        try:\n",
    "            train_data_frame.to_csv(TRAIN_DATA_PATH, index=False)\n",
    "            test_data_frame.to_csv(TEST_DATA_PATH, index=False)\n",
    "            validation_data_frame.to_csv(VALIDATION_DATA_PATH, index=False)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"An unexpected error occurred when saving datasets to CSV files: {e}\")\n",
    "\n",
    "    # Creating Datasets from the stored datasets\n",
    "    logger.info(f\"INITIALIZING DATASETS\")\n",
    "    train_dataset = CustomDataset(TRAIN_DATA_PATH)\n",
    "    test_dataset = CustomDataset(TEST_DATA_PATH)\n",
    "    val_dataset = CustomDataset(VALIDATION_DATA_PATH)\n",
    "\n",
    "    # Initialize the Different DataLoaders using the Datasets\n",
    "    logger.info(f\"Creating DataLoaders with 'batch_size'=({batch_size}), 'num_workers'=({num_workers}), 'pin_memory'=({pin_memory}). Training dataset 'drop_last'=({drop_last})\")\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory, drop_last=drop_last, shuffle=True)\n",
    "    validation_dataloader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory, drop_last=drop_last, shuffle=False)\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory, drop_last=drop_last, shuffle=False)\n",
    "\n",
    "    print(f\"Training DataLoader has ({len(train_dataloader)}) batches, Test DataLoader has ({len(test_dataloader)}) batches, Validation DataLoader has ({len(validation_dataloader)}) batches\")\n",
    "\n",
    "    return (train_dataset, test_dataset, val_dataset, train_dataloader, test_dataloader, validation_dataloader, feature_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305fc881",
   "metadata": {},
   "source": [
    "## Agent Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c2145",
   "metadata": {},
   "source": [
    "### Module Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c03975dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModuleLayer(torch.nn.Module):\n",
    "    \"\"\"Class for the individual layer blocks.\"\"\"\n",
    "    def __init__(self, intermediate_dim=32, dropout_rate=0.1):\n",
    "        \"\"\"Initializer for the 'ModuleLayer' class.\n",
    "        Args:\n",
    "            intermediate_dim (int): The dimension of the intermediate layer.\n",
    "            dropout_rate (float): The dropout rate to apply after the ReLU activation.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mod_linear = torch.nn.Linear(in_features=intermediate_dim, out_features=intermediate_dim)\n",
    "        self.mod_norm = torch.nn.LayerNorm(normalized_shape=intermediate_dim)\n",
    "        self.mod_relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the layer block.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor passing the input through the layer operations.\"\"\"\n",
    "        residual = x\n",
    "        x = self.mod_linear(x)\n",
    "        x = self.mod_norm(x)\n",
    "        x = self.mod_relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x += residual\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d1f835",
   "metadata": {},
   "source": [
    "### Agent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c24ad4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherAgent(torch.nn.Module):\n",
    "    \"\"\"Class for Agent Structure using multiple Layer Blocks.\"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        \"\"\"Initializer for the 'Agent' class.\n",
    "        Args:\n",
    "            cfg (dict): Configuration dictionary containing model parameters.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(in_features=cfg[\"in_dim\"], out_features=cfg[\"intermediate_dim\"])\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            *[ModuleLayer(intermediate_dim=cfg[\"intermediate_dim\"], dropout_rate=cfg[\"dropout_rate\"]) for _ in range(cfg[\"num_blocks\"])]\n",
    "        )\n",
    "        self.out = torch.nn.Linear(in_features=cfg[\"intermediate_dim\"], out_features=cfg[\"out_dim\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the Agent's Layers.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "        Returns:\n",
    "            x (torch.Tensor): Output tensor after passing through the network.\n",
    "        \"\"\"\n",
    "        x = self.linear(x)\n",
    "        x = self.layers(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b962ab",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bdd5d1",
   "metadata": {},
   "source": [
    "### Log Iteration Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c99dfaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_iteration(logger: Logger, batch_idx: int, total_batches: int, loss_value: float) -> None:\n",
    "    \"\"\"Logs the loss of the current batch.\"\"\"\n",
    "    logger.info(f\"Epoch batch [{batch_idx}/{total_batches}] | Loss: {loss_value:.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dda76fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_epoch_iteration(logger: Logger, epoch: int, avg_epoch_loss: float) -> None:\n",
    "    \"\"\"Log Current Metrics accumulated in the current epoch iteration.\n",
    "    Args:\n",
    "        epoch (int): the current iteration\n",
    "        avg_epoch_loss (float): The average loss of the current epoch.\"\"\"\n",
    "    if avg_epoch_loss:\n",
    "        logger.info(f\"=====================  [EPOCH ({epoch}) LOGGING]  =====================\")\n",
    "        logger.info(\"| AVERAGES of THIS EPOCH:\")\n",
    "        logger.info(f\"| ACCUMULATED LOSS: {avg_epoch_loss:.7f}\")\n",
    "        logger.info(f\"===========================================================\")\n",
    "\n",
    "    else:\n",
    "        logger.warning(\"No Data collected for this epoch to log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752b4c1",
   "metadata": {},
   "source": [
    "### Evaluate Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41ec95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(logger: Logger, model: Module, dataloader: DataLoader, current_epoch: int = None, max_epochs: int=None, device: str = 'cpu') -> float:\n",
    "    \"\"\"\n",
    "    Evaluates the model on a given dataset and returns the average loss.\n",
    "    Args:\n",
    "        logger (Logger): The logger instance to log messages.\n",
    "        model (Module): The Model.\n",
    "        dataloader (DataLoader): The dataloader to calculate average loss with.\n",
    "        current_epoch (int): The current epoch [optional].\n",
    "        max_epochs (int): The maximum number of epochs [optional].\n",
    "        device (str): The device that the calculations will take place on.\n",
    "    Returns:\n",
    "        avg_loss (float): The calculated average loss.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    # loss_fn = torch.nn.MELoss(reduction='sum') # Use reduction='sum' instead of 'mean' for total loss\n",
    "    loss_fn = torch.nn.L1Loss(reduction='sum')\n",
    "    if len(dataloader.dataset) == 0:\n",
    "        logger.warning(\"Warning: Evaluation dataset is empty. Skipping evaluation.\")\n",
    "        return float('nan')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_inputs, batch_labels in dataloader:\n",
    "            batch_inputs, batch_labels = batch_inputs.to(device), batch_labels.unsqueeze(dim=-1).to(device)\n",
    "            outputs = model(batch_inputs)\n",
    "            loss = loss_fn(outputs, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)     # Calculate the average loss on the dataset\n",
    "\n",
    "    if current_epoch and max_epochs:   # If the function was called in the training loop\n",
    "        logger.info(f\"===================  [Epoch ({current_epoch}/{max_epochs})]  ===================\")\n",
    "        logger.info(f\"Entire Validation Dataset Average Loss: {avg_loss:.4f}\")\n",
    "        logger.info(f\"====================================================\")\n",
    "\n",
    "    else:   # If the function was called outside of the training loop\n",
    "        logger.info(f\"===============================================\")\n",
    "        logger.info(f\"Entire Dataset Average Loss: {avg_loss:.4f} \")\n",
    "        logger.info(f\"=====================================================\")\n",
    "            \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6255bf",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d4a2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(logger: Logger, model_config: dict, training_config: dict, train_dataloader: DataLoader, validation_dataloader: DataLoader, model: WeatherAgent = None, epochs=32, learning_rate=0.0003, max_grad_norm=0.5, log_iterations=10, eval_iterations=10, device=\"cpu\") -> tuple[WeatherAgent, dict]:\n",
    "    \"\"\"The Model Training function.\n",
    "    Args:\n",
    "        logger (Logger): The logger instance to log messages.\n",
    "        model_config (dict): The base configurations for building the policies.\n",
    "        training_config (dict): The base configurations for training the model.\n",
    "        train_dataloader (DataLoader): The dataloader for the training loop.\n",
    "        validation_dataloader (DataLoader): The dataloader for the validation loop.\n",
    "        model (WeatherAgent): The model to be trained.\n",
    "        epochs (int): The number of times the outer loop is performed.\n",
    "        learning_rate (float): The hyperparameter that affects how much the model's parameters learn on each update iteration.\n",
    "        max_grad_norm (float): Used to promote numerical stability and prevent exploding gradients.\n",
    "        log_iterations (int): Used to log information about the state of the Agent.\n",
    "        eval_iterations (int): Used to run an evaluation of the Agent.\n",
    "        device (str): The device that the model will be trained on.\n",
    "    Returns: \n",
    "        agent (Module): The Trained Model in evaluation mode.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Training Model on 'device'=({device}) with ({epochs}) main epoch(s), learning rate=({learning_rate}), max_grad_norm=({max_grad_norm}).\")\n",
    "    logger.info(f\"Logging every ({log_iterations}) epoch iterations, and evaluating every ({eval_iterations}) epoch iterations.\")\n",
    "\n",
    "    agent = (model if model is not None else WeatherAgent(model_config)).to(device) # Create agent if nothing was passed, otherwise, create the agent. Send agent to device.\n",
    "\n",
    "    optim_choice = training_config.get(\"optimizer\", \"AdamW\").lower()\n",
    "    if optim_choice == \"adamw\":\n",
    "        optimizer = torch.optim.AdamW(params=agent.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    # Elif more optimizers are added in the future, they can be added here\n",
    "    elif optim_choice == \"adam\":\n",
    "        optimizer = torch.optim.AdamW(params=agent.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {optim_choice}\")\n",
    "\n",
    "    loss_choice = training_config.get(\"loss_function\", \"mae\").lower()\n",
    "    if loss_choice == \"mae\":\n",
    "        loss_fn = torch.nn.L1Loss(reduction='mean')      # Define the Loss function\n",
    "    # Elif more loss functions are added in the future, they can be added here\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported loss function: {loss_choice}\")\n",
    "\n",
    "\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "\n",
    "    train_dataloader_length = len(train_dataloader)\n",
    "    agent.train()   # Set agent to training mode\n",
    "\n",
    "    # Loop over the number of epochs\n",
    "    for epoch in tqdm(range(epochs), desc=f\">>>>>>>>>>>>>>>>>>>>>\\nMain Epoch (Outer Loop)\", leave=True):\n",
    "\n",
    "        epoch_loss_total = 0.0\n",
    "        for batch_idx, (inputs, labels) in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs} - Training\", leave=False)):           # Get a mini-batch of training examples from the dataloader\n",
    "            # optimizer.zero_grad(set_to_none=True)       # Clear the gradients built up; Setting to None to improve performance\n",
    "            optimizer.zero_grad()       # Clear the gradients built up\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.unsqueeze(dim=-1).to(device)   # Move the inputs and labels to the device\n",
    "\n",
    "            agent_outputs = agent(inputs)       # Pass the inputs to the model and get the outputs.\n",
    "\n",
    "            loss = loss_fn(agent_outputs, labels)      # Calculate the mini-batch loss\n",
    "            epoch_loss_total += loss.item()\n",
    "\n",
    "            loss.backward()         # Calculate the loss with respect to the model parameters\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=agent.parameters(), max_norm=max_grad_norm)   # Prevent the gradients from affecting the model parameters too much and reduce the risk of exploding gradients\n",
    "\n",
    "            optimizer.step()      # Update the model's parameters using the learning rate\n",
    "\n",
    "            # LOGGING LOSS OF CURRENT ITERATION\n",
    "            if (batch_idx + 1) % log_iterations == 0:\n",
    "                log_iteration(logger, batch_idx=(batch_idx + 1), total_batches=train_dataloader_length, loss_value=loss.item())\n",
    "\n",
    "        # CALCULATE AND STORE THE AVERAGE EPOCH LOSS\n",
    "        epoch_avg_loss = epoch_loss_total / train_dataloader_length\n",
    "        history[\"train_loss\"].append(epoch_avg_loss)\n",
    "\n",
    "        # LOG THE AVERAGE LOSS OF THE EPOCH\n",
    "        log_epoch_iteration(logger, epoch=epoch, avg_epoch_loss=epoch_avg_loss)\n",
    "\n",
    "        # EVALUATE THE MODEL\n",
    "        if (epoch + 1) % eval_iterations == 0:\n",
    "            val_loss = evaluate_model(logger, model=agent, dataloader=validation_dataloader, current_epoch=(epoch + 1), max_epochs=epochs, device=device)\n",
    "            history[\"val_loss\"].append(val_loss)\n",
    "            agent.train()   # Set agent to training mode\n",
    "\n",
    "\n",
    "    return agent.eval(), history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72b7a9d",
   "metadata": {},
   "source": [
    "## Miscelaneous Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e53a01",
   "metadata": {},
   "source": [
    "### Checks for current running mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f98a7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_notebook():\n",
    "    \"\"\"Checks if the code is running in a Jupyter notebook environment.\n",
    "    Returns:\n",
    "        bool: True if running in a Jupyter notebook, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "\n",
    "        # print(f\"Detected shell: {shell}\", flush=True)\n",
    "\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other types\n",
    "    except NameError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d32a7f",
   "metadata": {},
   "source": [
    "### Convert json to arg list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb3f2159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_arg_list(arg_dict) -> List[str]:\n",
    "    \"\"\"Converts a dictionary of arguments to a list suitable for argparse.\n",
    "    Args:\n",
    "        arg_dict (dict): Dictionary of arguments where keys are argument names and values are argument values.\n",
    "    Returns:\n",
    "        args (list): List of arguments formatted for argparse.\n",
    "    \"\"\"\n",
    "\n",
    "    args = []\n",
    "    for key, value in arg_dict.items():\n",
    "\n",
    "        # print(f\"Processing key: {key}, value: {value} type: {type(value)}\")\n",
    "\n",
    "        # Checks if the value is a boolean flag\n",
    "        if value is False or value is True:\n",
    "            # Only add the flag if it's True\n",
    "            if value:\n",
    "                args.append(key)\n",
    "        else:\n",
    "            # Add both the key and its value\n",
    "            args.append(key)\n",
    "            args.append(str(value))\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d9fc8c",
   "metadata": {},
   "source": [
    "### Creating Logger Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "735ad9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(config: dict, propogate: bool=False) -> Logger:\n",
    "    \"\"\"Sets up and returns a named logger based on the provided config dictionary. The new logger will have different handlers based on the config.\n",
    "    \n",
    "    Args:\n",
    "        config (dict): Dictionary containing logging configuration.\n",
    "        propogate (bool): Whether to allow log messages to propagate to ancestor loggers.\n",
    "    Returns:\n",
    "        Logger: Configured logger instance.\"\"\"\n",
    "\n",
    "    logger_name = config.get('logger_name', 'main')\n",
    "    log_to_file = config.get('log_to_file', True)   # Set whether to log to a logfile or not\n",
    "    log_file = config.get('log_file', 'logs/app.log') # Get the log file path\n",
    "    log_lvl = config.get('log_level', 'INFO')\n",
    "    log_level = getattr(logging, log_lvl.upper(), logging.INFO) # Set fallback if invalid input\n",
    "    log_mode = config.get('log_mode', 'w') # Set the log file mode\n",
    "    log_format = config.get('log_format', '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    date_format = config.get('date_format', '%Y-%m-%d %H:%M:%S')\n",
    "    log_to_console = config.get('log_to_console', True) # Set whether to log to console or not\n",
    "\n",
    "    handlers = []   # Initialize the list of logging handlers\n",
    "\n",
    "    logger = logging.getLogger(logger_name) # Create logger object with the specified name\n",
    "\n",
    "    if not log_to_file and not log_to_console:\n",
    "        # If no handlers are specified by the config\n",
    "        print(f\"Warning: No logging handlers configured for {logger_name}.\\nVerbose Logging will be disabled.\\nIn 'config/config.json', set ['log_to_file': true] or ['log_to_console': true] if you want to change the logging behavior.\", flush=True)\n",
    "    else:\n",
    "        # Create log parent directory if it doesn't exist\n",
    "        parent_dir = os.path.dirname(log_file) # Get the parent directory of the log file\n",
    "        if parent_dir and parent_dir != '.':\n",
    "            try:\n",
    "                os.makedirs(name=parent_dir, exist_ok=True)\n",
    "                print(f\"Parent directory '{parent_dir}' used to store the log file.\", flush=True)   # flush=True to ensure the message is printed immediately\n",
    "            except OSError as e:\n",
    "                print(f\"Error creating directory '{parent_dir}': {e} INFO: Using default log file 'app.log' instead.\", flush=True)\n",
    "                log_file='app.log'      # Fall back to a default log file if problem occurs.\n",
    "\n",
    "        # Remove all old handlers inherrited from the root logger\n",
    "        for handler in logger.handlers[:]:\n",
    "            handler.close()\n",
    "            logger.removeHandler(handler)\n",
    "\n",
    "        formatter = logging.Formatter(fmt=log_format, datefmt=date_format)   # Create a formatter for the log messages\n",
    "\n",
    "        if log_to_console:\n",
    "            console_handler = logging.StreamHandler() # Initialize sending log messages to the console (stdout)\n",
    "            console_handler.setFormatter(formatter)  # Set the formatter for the console handler\n",
    "            handlers.append(console_handler)    # Add the console_handler to the list of handlers\n",
    "        if log_to_file:\n",
    "            file_handler = logging.FileHandler(filename=log_file, mode=log_mode)    # Initialize sending log messages to a file\n",
    "            file_handler.setFormatter(formatter)  # Set the style for the console handler\n",
    "            handlers.append(file_handler)   # Add the file_handler to the list of handlers\n",
    "\n",
    "        # Add the handlers to the logger\n",
    "        for handler in handlers:\n",
    "            logger.addHandler(handler)\n",
    "\n",
    "    logger.setLevel(log_level)  # Set logger minimum log level\n",
    "\n",
    "    logger.propagate = propogate   # Prevent the log messages from being propagated to the root logger; gets rid of the root logger's default handlers\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad033e06",
   "metadata": {},
   "source": [
    "### Retrieve Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "804dbb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_logger(name: str = 'root') -> Logger:\n",
    "    \"\"\"\n",
    "    Retrieves a named logger. If no handlers are attached, returns a root logger instance.\n",
    "    Args:\n",
    "        name (str): The name of the logger to retrieve.\n",
    "    Returns:\n",
    "        Logger: The logger instance.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "\n",
    "    if not logger.handlers:\n",
    "        print(f\"Retrieving root logger.\", flush=True)\n",
    "        return logging.getLogger()\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7673d8ca",
   "metadata": {},
   "source": [
    "### Close file handlers and exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0b32d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_and_exit(logger: Logger, exit_code: int) -> None:\n",
    "    \"\"\"Closes all handlers of the logger and exits the program with the given exit code.\n",
    "    Args:\n",
    "        logger (Logger): The logger instance to close.\n",
    "        exit_code (int): The exit code to terminate the program with.\n",
    "    \"\"\"\n",
    "    print(\"Note: Closing any named loggers...\", flush=True)\n",
    "    used_handlers = logger.handlers[:]\n",
    "    for handler in used_handlers:\n",
    "        handler.close()\n",
    "        logger.removeHandler(handler)\n",
    "\n",
    "    print(\"Note: Closing any root logger...\", flush=True)\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        handler.close()\n",
    "        logging.root.removeHandler(handler)\n",
    "\n",
    "    print(f\"Exiting program with exit code {exit_code}.\", flush=True)\n",
    "\n",
    "    if is_notebook():\n",
    "        print(\"Detected Jupyter Notebook environment. Skipping sys.exit() to avoid kernel interruption.\", flush=True)\n",
    "    else:\n",
    "        sys.exit(exit_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8551e5a3",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9396d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(parser_args, global_config) -> int:\n",
    "    \"\"\"Main function to run the script pipeline.\n",
    "    Args:\n",
    "        parser_args: The arguments from the argument parser.\n",
    "        global_config: The arguments from the config file.\n",
    "    Returns:\n",
    "        int: Exit code (0 for success, non-zero for failure).\n",
    "    \"\"\"\n",
    "    # Create logger object\n",
    "    logger = retrieve_logger(global_config[\"logging\"][\"logger_name\"])\n",
    "    logger.info(\"STARTING MAIN FUNCTION\")\n",
    "\n",
    "    if parser_args.device == 'cpu' or parser_args.device == 'cuda':     # Check if the user specified to use a CPU or GPU for training\n",
    "        DEVICE = parser_args.device\n",
    "    else:\n",
    "        if parser_args.use_cuda:   # Check if the user wanted to use CUDA if available.\n",
    "            DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            logger.info(\"Defaulted to using CPU for training.\")\n",
    "            DEVICE = 'cpu'\n",
    "\n",
    "    SAVE_LOCATION = global_config[\"parser_defaults\"][\"model_output_path\"]   # Get the model save destination path\n",
    "\n",
    "    BASE_CONFIG=global_config[\"model\"]\n",
    "    TRAINING_CONFIG=global_config[\"training\"]\n",
    "    PIPELINE_CONFIG=global_config[\"data\"]\n",
    "\n",
    "    # --- Data Preparation Pipeline ---\n",
    "    logger.info(\"RUNNING THE DATA PIPELINE\")\n",
    "    try:\n",
    "        # Use dictionary unpacking to pass the PIPELINE_CONFIG parameters to the data_pipeline function\n",
    "        (train_dataset, test_dataset, validation_dataset, train_dataloader, test_dataloader, validation_dataloader, feature_scaler) = data_pipeline(logger=logger, **PIPELINE_CONFIG, batch_size=parser_args.dataloader_batch_size, num_workers=parser_args.dataloader_num_workers, pin_memory=parser_args.dataloader_pin_memory, drop_last=True)\n",
    "\n",
    "    except ValueError as e:\n",
    "        logger.error(f\"Caught a 'value' error: {e}\", exc_info=True, stack_info=True)\n",
    "        return 1\n",
    "    except RuntimeError as e:\n",
    "        logger.error(f\"Caught a 'runtime' error: {e}\", exc_info=True, stack_info=True)\n",
    "        return 1\n",
    "\n",
    "    logger.info(\"BEGINNING TRAINING SCRIPT\")\n",
    "    start_time=time.time()\n",
    "\n",
    "    try:\n",
    "        trained_policy, training_history = train_model(\n",
    "            logger=logger,\n",
    "            model_config=BASE_CONFIG,\n",
    "            training_config=TRAINING_CONFIG,\n",
    "            train_dataloader=train_dataloader,\n",
    "            validation_dataloader=validation_dataloader,\n",
    "            model=None,     # Create new model\n",
    "            epochs=parser_args.epochs,\n",
    "            learning_rate=parser_args.learning_rate,\n",
    "            max_grad_norm=parser_args.max_grad_norm,\n",
    "            log_iterations=parser_args.log_iterations,\n",
    "            eval_iterations=parser_args.eval_iterations,\n",
    "            device=DEVICE,\n",
    "        )\n",
    "    except MemoryError as e:\n",
    "        logger.error(f\"Memory Error: {e}. Consider reducing the DataLoader's batch size or model complexity.\", exc_info=True, stack_info=True)\n",
    "        return 1\n",
    "    except KeyboardInterrupt:\n",
    "        logger.error(\"Training interrupted by user (KeyboardInterrupt).\", exc_info=True, stack_info=True)\n",
    "        return 1\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during model training: {e}\", exc_info=True, stack_info=True)\n",
    "        return 1\n",
    "    end_time=time.time()\n",
    "\n",
    "    # --- Calculate Training Time ---\n",
    "\n",
    "    elapsed_time= end_time - start_time\n",
    "    hrs = int(elapsed_time / 3600)\n",
    "    min = int((elapsed_time % 3600) / 60)\n",
    "    seconds_remaining = elapsed_time - (hrs * 3600 ) - (min * 60)\n",
    "\n",
    "    logger.info(f\"FINISHED MODEL TRAINING\")\n",
    "    logger.info(f\"TRAINING TOOK: {hrs} Hours, {min} Minutes, and {seconds_remaining:.3f} Seconds\")\n",
    "\n",
    "    # --- Training History Section  ---\n",
    "    logger.info(\"TRAINING HISTORY:\")\n",
    "    logger.info(training_history)\n",
    "\n",
    "    # --- Testing Trained Model ---\n",
    "    logger.info(\"TESTING THE TRAINED POLICY:\")\n",
    "    test_loss = evaluate_model(logger=logger, model=trained_policy, dataloader=test_dataloader, current_epoch=None, max_epochs=None, device='cpu')\n",
    "\n",
    "    # ---  Saving Model Section  ---\n",
    "    if parser_args.save_model:     # Check if the user wants to save the trained model weights\n",
    "        logger.info(\"SAVING THE TRAINED POLICY:\")\n",
    "        if parser_args.model_output_path:     # Check if the user specified a target save location\n",
    "            SAVE_LOCATION=parser_args.model_output_path\n",
    "\n",
    "        parent_dir = os.path.dirname(SAVE_LOCATION) # Get the parent directory of the model's save location\n",
    "        # Create the parent directory if it doesn't exist\n",
    "        # If parent_dir is empty, it means the SAVE_LOCATION is just a filename or\n",
    "        # in the current directory, so no new directories need to be created.\n",
    "        if parent_dir and parent_dir != '.':\n",
    "            try:\n",
    "                os.makedirs(parent_dir, exist_ok=True)\n",
    "                logger.info(f\"Parent directory '{parent_dir}' used to store the model.\")\n",
    "            except OSError as e:\n",
    "                logger.error(f\"Error creating directory {parent_dir}: {e}\", exc_info=True, stack_info=True)\n",
    "                SAVE_LOCATION='model.pt'      # Fall back to a default save location if problem occurs.\n",
    "\n",
    "        try:\n",
    "            torch.save(trained_policy.state_dict(), f=SAVE_LOCATION)\n",
    "            logger.info(f\"Model weights saved in: {SAVE_LOCATION}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving model to {SAVE_LOCATION}: {e}\", exc_info=True, stack_info=True)\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578429ae",
   "metadata": {},
   "source": [
    "## Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d387cce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent directory 'logs' used to store the log file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-07 09:59:08 - main - INFO - Namespace(epochs=8, learning_rate=0.003, max_grad_norm=3.0, dataloader_batch_size=64, dataloader_pin_memory=False, dataloader_num_workers=0, log_iterations=256, eval_iterations=64, use_cuda=False, device='cpu', save_model=False, model_output_path='weather-agent.pt')\n",
      "2025-10-07 09:59:08 - main - INFO - CALLING MAIN SCRIPT...\n",
      "2025-10-07 09:59:08 - main - INFO - STARTING MAIN FUNCTION\n",
      "2025-10-07 09:59:08 - main - INFO - RUNNING THE DATA PIPELINE\n",
      "2025-10-07 09:59:08 - main - INFO - root_data_dir: ./Data\n",
      "2025-10-07 09:59:08 - main - INFO - CSV file detected, reading from 'Data'\n",
      "2025-10-07 09:59:08 - main - INFO - INITIALIZING DATASETS\n",
      "2025-10-07 09:59:08 - main - INFO - Creating DataLoaders with 'batch_size'=(64), 'num_workers'=(0), 'pin_memory'=(False). Training dataset 'drop_last'=(True)\n",
      "2025-10-07 09:59:08 - main - INFO - BEGINNING TRAINING SCRIPT\n",
      "2025-10-07 09:59:08 - main - INFO - Training Model on 'device'=(cpu) with (8) main epoch(s), learning rate=(0.003), max_grad_norm=(3.0).\n",
      "2025-10-07 09:59:08 - main - INFO - Logging every (256) epoch iterations, and evaluating every (64) epoch iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Test, and Validation csv datasets detected in 'Data\\DataSplits', skipping generation and loading scaler(s)\n",
      "Training DataLoader has (209) batches, Test DataLoader has (11) batches, Validation DataLoader has (11) batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>\n",
      "Main Epoch (Outer Loop):   0%|          | 0/8 [00:00<?, ?it/s]2025-10-07 09:59:28 - main - INFO - =====================  [EPOCH (0) LOGGING]  =====================\n",
      "2025-10-07 09:59:28 - main - INFO - | AVERAGES of THIS EPOCH:\n",
      "2025-10-07 09:59:28 - main - INFO - | ACCUMULATED LOSS: 5.8212481\n",
      "2025-10-07 09:59:28 - main - INFO - ===========================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>\n",
      "Main Epoch (Outer Loop):  12%|█▎        | 1/8 [00:13<01:35, 13.69s/it]2025-10-07 09:59:37 - main - INFO - =====================  [EPOCH (1) LOGGING]  =====================\n",
      "2025-10-07 09:59:37 - main - INFO - | AVERAGES of THIS EPOCH:\n",
      "2025-10-07 09:59:37 - main - INFO - | ACCUMULATED LOSS: 3.9316069\n",
      "2025-10-07 09:59:37 - main - INFO - ===========================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>\n",
      "Main Epoch (Outer Loop):  25%|██▌       | 2/8 [00:22<01:06, 11.09s/it]2025-10-07 09:59:47 - main - INFO - =====================  [EPOCH (2) LOGGING]  =====================\n",
      "2025-10-07 09:59:47 - main - INFO - | AVERAGES of THIS EPOCH:\n",
      "2025-10-07 09:59:47 - main - INFO - | ACCUMULATED LOSS: 3.9155214\n",
      "2025-10-07 09:59:47 - main - INFO - ===========================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>\n",
      "Main Epoch (Outer Loop):  38%|███▊      | 3/8 [00:32<00:52, 10.54s/it]2025-10-07 09:59:55 - main - INFO - =====================  [EPOCH (3) LOGGING]  =====================\n",
      "2025-10-07 09:59:55 - main - INFO - | AVERAGES of THIS EPOCH:\n",
      "2025-10-07 09:59:55 - main - INFO - | ACCUMULATED LOSS: 3.8855226\n",
      "2025-10-07 09:59:55 - main - INFO - ===========================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>\n",
      "Main Epoch (Outer Loop):  50%|█████     | 4/8 [00:41<00:39,  9.77s/it]2025-10-07 10:00:06 - main - INFO - =====================  [EPOCH (4) LOGGING]  =====================\n",
      "2025-10-07 10:00:06 - main - INFO - | AVERAGES of THIS EPOCH:\n",
      "2025-10-07 10:00:06 - main - INFO - | ACCUMULATED LOSS: 3.8669411\n",
      "2025-10-07 10:00:06 - main - INFO - ===========================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>\n",
      "Main Epoch (Outer Loop):  62%|██████▎   | 5/8 [00:51<00:29,  9.90s/it]2025-10-07 10:00:15 - main - INFO - =====================  [EPOCH (5) LOGGING]  =====================\n",
      "2025-10-07 10:00:15 - main - INFO - | AVERAGES of THIS EPOCH:\n",
      "2025-10-07 10:00:15 - main - INFO - | ACCUMULATED LOSS: 3.8647464\n",
      "2025-10-07 10:00:15 - main - INFO - ===========================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>\n",
      "Main Epoch (Outer Loop):  75%|███████▌  | 6/8 [01:00<00:19,  9.68s/it]2025-10-07 10:00:24 - main - INFO - =====================  [EPOCH (6) LOGGING]  =====================\n",
      "2025-10-07 10:00:24 - main - INFO - | AVERAGES of THIS EPOCH:\n",
      "2025-10-07 10:00:24 - main - INFO - | ACCUMULATED LOSS: 3.8758088\n",
      "2025-10-07 10:00:24 - main - INFO - ===========================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>\n",
      "Main Epoch (Outer Loop):  88%|████████▊ | 7/8 [01:10<00:09,  9.53s/it]2025-10-07 10:00:33 - main - INFO - =====================  [EPOCH (7) LOGGING]  =====================\n",
      "2025-10-07 10:00:33 - main - INFO - | AVERAGES of THIS EPOCH:\n",
      "2025-10-07 10:00:33 - main - INFO - | ACCUMULATED LOSS: 3.8544391\n",
      "2025-10-07 10:00:33 - main - INFO - ===========================================================\n",
      ">>>>>>>>>>>>>>>>>>>>>\n",
      ">>>>>>>>>>>>>>>>>>>>>p): 100%|██████████| 8/8 [01:19<00:00,  9.44s/it]\n",
      "Main Epoch (Outer Loop): 100%|██████████| 8/8 [01:19<00:00,  9.91s/it]\n",
      "2025-10-07 10:00:33 - main - INFO - FINISHED MODEL TRAINING\n",
      "2025-10-07 10:00:33 - main - INFO - TRAINING TOOK: 0 Hours, 1 Minutes, and 24.889 Seconds\n",
      "2025-10-07 10:00:33 - main - INFO - TRAINING HISTORY:\n",
      "2025-10-07 10:00:33 - main - INFO - {'train_loss': [5.821248127512955, 3.9316069292679927, 3.915521359329589, 3.885522606270165, 3.8669410653091503, 3.8647464393999016, 3.875808847007569, 3.8544391410772882], 'val_loss': []}\n",
      "2025-10-07 10:00:33 - main - INFO - TESTING THE TRAINED POLICY:\n",
      "2025-10-07 10:00:33 - main - INFO - ===============================================\n",
      "2025-10-07 10:00:33 - main - INFO - Entire Dataset Average Loss: 3.4336 \n",
      "2025-10-07 10:00:33 - main - INFO - =====================================================\n",
      "2025-10-07 10:00:33 - main - INFO - FINISHED MAIN SCRIPT\n",
      "2025-10-07 10:00:33 - main - INFO - OVERALL DURATION: 0 Hours, 1 Minutes, and 25.237 Seconds\n",
      "2025-10-07 10:00:33 - main - INFO - TERMINATING PROGRAM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Closing any named loggers...\n",
      "Note: Closing any root logger...\n",
      "Exiting program with exit code 0.\n",
      "Detected Jupyter Notebook environment. Skipping sys.exit() to avoid kernel interruption.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # --- Begin Timing Main Script Execution Time ---\n",
    "    main_start_time=time.time()\n",
    "\n",
    "    #  --- Load Config File ---\n",
    "    try:\n",
    "        with open(file=CONFIG_PATH, mode='r', encoding='utf-8') as f:\n",
    "            json_args = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Config file not found. Please ensure '{CONFIG_PATH}' exists. Modify 'CONFIG_PATH' in Global Variables section if needed.\", flush=True)\n",
    "        sys.exit(1)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Unexpected runtime error loading config file: {e}. Exiting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # --- Logging Initialization Section ---\n",
    "    log_to_console = json_args['logging']['log_to_console'] # Set whether to log to console or not\n",
    "    log_to_file = json_args['logging']['log_to_file']   # Set whether to log to a logfile or not\n",
    "    logger_config = json_args['logging']\n",
    "\n",
    "    # Configure the root logger for any backup logging\n",
    "    logging.basicConfig(level=logging.CRITICAL)  # Set root logger to highest level to suppress unwanted logs\n",
    "\n",
    "    # Create the named logger only if the user wants to log to console or file\n",
    "    if log_to_console or log_to_file:\n",
    "        logger = setup_logger(config=logger_config, propogate=False)\n",
    "    # Check if the user disabled both logging methods and resort to the root logger with no handlers\n",
    "    elif not log_to_file and not log_to_console:\n",
    "        print(f\"========================================\\nWarning: No logging handlers configured for logger, using root logger.\\nVerbose Logging will be disabled.\\nTraining progress will be shown using tqdm.\\nIf you want to change the logging behavior:\\nIn 'config/config.json', set ['log_to_file': true] or ['log_to_console': true]\\n========================================\\n \", flush=True)\n",
    "        logger = logging.getLogger()  # Use the root logger\n",
    "\n",
    "        # Remove all handlers inherrited from the root logger, if any exist\n",
    "        for handler in logger.handlers[:]:\n",
    "            handler.close()\n",
    "            logger.removeHandler(handler)\n",
    "\n",
    "    # --- Argument Parser Section ---\n",
    "    parser = argparse.ArgumentParser(description=\"Train and evaluate a Regression Agent.\")\n",
    "\n",
    "    parser.add_argument('--epochs', type=int, default=json_args[\"parser_defaults\"][\"epochs\"],\n",
    "        help=f'(int, default={json_args[\"parser_defaults\"][\"epochs\"]}) Number of training epochs to run.')\n",
    "\n",
    "    parser.add_argument('--learning_rate', type=float, default=json_args[\"parser_defaults\"][\"learning_rate\"],\n",
    "        help=f'(float, default={json_args[\"parser_defaults\"][\"learning_rate\"]}) Learning rate used by the optimizer.')\n",
    "\n",
    "    parser.add_argument('--max_grad_norm', type=float, default=json_args[\"parser_defaults\"][\"max_grad_norm\"],\n",
    "        help=f'(float, default={json_args[\"parser_defaults\"][\"max_grad_norm\"]}) The Maximum L2 Norm of the gradients for Gradient Clipping.')\n",
    "\n",
    "    parser.add_argument('--dataloader_batch_size', type=int, default=json_args[\"parser_defaults\"][\"dataloader_batch_size\"],\n",
    "        help=f'(int, default={json_args[\"parser_defaults\"][\"dataloader_batch_size\"]}) Batch size used by the dataloaders for training, validation, and testing.')\n",
    "\n",
    "    parser.add_argument('--dataloader_pin_memory', action='store_true',\n",
    "        help='(bool, default=False) Toggle pinned memory in dataloaders (disabled by default).')\n",
    "\n",
    "    parser.add_argument('--dataloader_num_workers', type=int, default=json_args[\"parser_defaults\"][\"dataloader_num_workers\"],\n",
    "        help=f'(int, default={json_args[\"parser_defaults\"][\"dataloader_num_workers\"]}) Number of subprocesses to use for data loading.')\n",
    "\n",
    "    parser.add_argument('--log_iterations', type=int, default=json_args[\"parser_defaults\"][\"log_iterations\"],\n",
    "        help=f'(int, default={json_args[\"parser_defaults\"][\"log_iterations\"]}) Frequency (in iterations) to log training progress.')\n",
    "\n",
    "    parser.add_argument('--eval_iterations', type=int, default=json_args[\"parser_defaults\"][\"eval_iterations\"],\n",
    "        help=f'(int, default={json_args[\"parser_defaults\"][\"eval_iterations\"]}) Frequency (in iterations) to evaluate the model.')\n",
    "\n",
    "    parser.add_argument('--use_cuda', action='store_true',\n",
    "        help='(bool, default=False) Enable CUDA for training if available.')\n",
    "\n",
    "    parser.add_argument('--device', type=str, default=json_args[\"parser_defaults\"][\"device\"],\n",
    "        help=f'(str, default={json_args[\"parser_defaults\"][\"device\"]}) Device to use for training (e.g., \"cpu\", \"cuda:0\"). Overrides --use_cuda.')\n",
    "\n",
    "    parser.add_argument('--save_model', action='store_true',\n",
    "        help='(bool, default=False) Save the trained model after training.')\n",
    "\n",
    "    parser.add_argument('--model_output_path', type=str, default=json_args[\"parser_defaults\"][\"model_output_path\"],\n",
    "        help=f'(str, default={json_args[\"parser_defaults\"][\"model_output_path\"]}) File path to save the trained model.')\n",
    "\n",
    "    # --- Parse the argparse arguments ---\n",
    "\n",
    "    if is_notebook():\n",
    "        # --- Simulate command-line arguments for testing purposes (IPYNB TESTING ONLY) ---\n",
    "        json_sim_args = json_args[\"simulated_args\"]\n",
    "        # Convert JSON args to list for argparse\n",
    "        simulated_args = json_to_arg_list(json_sim_args)\n",
    "\n",
    "        parser_args = parser.parse_args(args=simulated_args)   # Overrides the default values with the simulated values\n",
    "    else:   # Parse the argparse command-line arguments\n",
    "        parser_args = parser.parse_args()\n",
    "\n",
    "    # Log all of the passed parser arguments\n",
    "    logger.info(parser_args)\n",
    "\n",
    "    ## --- Call Main Script Section ---\n",
    "    logger.info(\"CALLING MAIN SCRIPT...\", exc_info=False, stack_info=False)\n",
    "\n",
    "    # Call the main function with both the parser arguments and the 'config.json' file\n",
    "    ret = main(parser_args, json_args)\n",
    "\n",
    "    main_end_time=time.time()\n",
    "\n",
    "    # --- Calculate Main Script Execution Time ---\n",
    "\n",
    "    elapsed_time= main_end_time - main_start_time\n",
    "    hrs = int(elapsed_time / 3600)\n",
    "    mins = int((elapsed_time % 3600) / 60)\n",
    "    seconds_remaining = elapsed_time - (hrs * 3600) - (mins * 60)\n",
    "\n",
    "    logger.info(f\"FINISHED MAIN SCRIPT\")\n",
    "    logger.info(f\"OVERALL DURATION: {hrs} Hours, {mins} Minutes, and {seconds_remaining:.3f} Seconds\")\n",
    "\n",
    "    # --- Determine final message based on return code ---\n",
    "    if ret == 0:\n",
    "        if not log_to_console and not log_to_file:\n",
    "            print(\"FINISHED MAIN SCRIPT.\\nCheck '/Models' folder for any saved model(s)\", flush=True)\n",
    "        else:\n",
    "            logger.info(\"TERMINATING PROGRAM\")\n",
    "    else:\n",
    "        if not log_to_console and not log_to_file:\n",
    "            print(\"MAIN SCIPT ERROR\", flush=True)\n",
    "        else:\n",
    "            logger.error(\"MAIN SCIPT ERROR\")\n",
    "\n",
    "    # --- Closes any logger file handlers and exits the program ---\n",
    "    close_and_exit(logger, ret)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WP_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
